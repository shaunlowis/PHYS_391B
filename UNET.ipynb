{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd2a107-83c6-4625-b863-858d887bc03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize \n",
    "\n",
    "# Don't Show Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b9f2f8-9797-42a0-aee2-a859c0d068e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "NUM_TEST_IMAGES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530bf895-a160-4cfa-9039-1a250477c6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>has_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_2016__1178.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_2016__3864.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_2016__8164.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_2016__5881.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_2016__6310.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015_2016__4945.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015_2016__061.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015_2016__4496.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015_2016__7826.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015_2016__4387.jpg</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_id has_mask\n",
       "0  2015_2016__1178.jpg      yes\n",
       "1  2015_2016__3864.jpg      yes\n",
       "2  2015_2016__8164.jpg      yes\n",
       "3  2015_2016__5881.jpg      yes\n",
       "4  2015_2016__6310.jpg      yes\n",
       "5  2015_2016__4945.jpg      yes\n",
       "6   2015_2016__061.jpg      yes\n",
       "7  2015_2016__4496.jpg      yes\n",
       "8  2015_2016__7826.jpg      yes\n",
       "9  2015_2016__4387.jpg      yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of files in each folder\n",
    "base = r'/home/shaun/data/merged'\n",
    "img_list = os.listdir(os.path.join(base, '2015_2016/tiles'))\n",
    "mask_list = os.listdir(os.path.join(base, 'outlines/tiles'))\n",
    "\n",
    "# create a dataframe\n",
    "df_images = pd.DataFrame(img_list, columns=['image_id'])\n",
    "\n",
    "# filter out the non image file that's called .htaccess\n",
    "df_images = df_images[df_images['image_id'] != '.htaccess']\n",
    "\n",
    "def check_for_mask(x):\n",
    "    if x in mask_list:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'\n",
    "    \n",
    "# create a new column called 'has_mask'\n",
    "df_images['has_mask'] = df_images['image_id'].apply(check_for_mask)\n",
    "\n",
    "df_masks = df_images[df_images['has_mask'] == 'yes']\n",
    "\n",
    "# create a new column called mask_id that is just a copy of image_id\n",
    "df_masks['mask_id'] = df_masks['image_id']\n",
    "\n",
    "df_masks.shape\n",
    "\n",
    "df_images.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e631b855-d9e4-4ee1-800a-5097ded45fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7898, 3)\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "# create a test set\n",
    "df_test = df_masks.sample(NUM_TEST_IMAGES, random_state=101)\n",
    "\n",
    "# Reset the index.\n",
    "# This is so that we can use loc to access mask id's later.\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# create a list of test images\n",
    "test_images_list = list(df_test['image_id'])\n",
    "\n",
    "# Select only rows that are not part of the test set.\n",
    "# Note the use of ~ to execute 'not in'.\n",
    "df_masks = df_masks[~df_masks['image_id'].isin(test_images_list)]\n",
    "\n",
    "print(df_masks.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f47ec81f-340c-4836-bc26-394813a2216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get lists of images and their masks.\n",
    "image_id_list = list(df_masks['image_id'])\n",
    "mask_id_list = list(df_masks['mask_id'])\n",
    "test_id_list = list(df_test['image_id'])\n",
    "\n",
    "# Create empty arrays\n",
    "\n",
    "X_train = np.zeros((len(image_id_list), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "Y_train = np.zeros((len(image_id_list), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "X_test = np.zeros((NUM_TEST_IMAGES, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921b5fe5-b6cd-49cd-8d4a-4e4d7feb010e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7898, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train\n",
    "\n",
    "for i, image_id in enumerate(image_id_list):\n",
    "    \n",
    "    path_image = os.path.join(base, '2015_2016/tiles', image_id)\n",
    "    \n",
    "    # read the image using skimage\n",
    "    image = imread(path_image)\n",
    "    \n",
    "    # resize the image\n",
    "    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    \n",
    "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    # image = np.expand_dims(image, axis=-1)\n",
    "    \n",
    "    # insert the image into X_train\n",
    "    X_train[i] = image\n",
    "    \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85fa793-537b-496f-bc79-3a97b51b8140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7898, 224, 224, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y_train\n",
    "\n",
    "for i, mask_id in enumerate(mask_id_list):\n",
    "    \n",
    "    path_mask = os.path.join(base, 'outlines/tiles', mask_id) \n",
    "    \n",
    "    # read the image using skimage\n",
    "    mask = imread(path_mask)\n",
    "    \n",
    "    # resize the image\n",
    "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "\n",
    "    mask = rgb2gray(mask)\n",
    "\n",
    "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    # insert the image into Y_Train\n",
    "    Y_train[i] = mask\n",
    "\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8deec68e-6f2d-40b7-9e3a-14830aafa11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test\n",
    "selected = ['2015_2016__69.jpg', '2015_2016__73.jpg', '2015_2016__094.jpg',\n",
    "            '2015_2016__79.jpg', '2015_2016__87.jpg', '2015_2016__097.jpg',\n",
    "            '2015_2016__104.jpg', '2015_2016__158.jpg', '2015_2016__170.jpg',\n",
    "            '2015_2016__180.jpg']\n",
    "\n",
    "# dense_blds = ['rolleston_13824_13312.jpeg', 'rolleston_13824_13824.jpeg', 'rolleston_14336_10752.jpeg',\n",
    "#               'rolleston_14336_11264.jpeg', 'rolleston_14336_11776.jpeg', 'rolleston_14336_25088.jpeg',\n",
    "#               'rolleston_14848_10240.jpeg', 'rolleston_14848_11264.jpeg', 'rolleston_15360_1536.jpeg',\n",
    "#               'rolleston_15360_6656.jpeg']\n",
    "\n",
    "for i, image_id in enumerate(selected):\n",
    "    \n",
    "    path_image = os.path.join(base, 'outlines/tiles', image_id)\n",
    "    \n",
    "    # read the image using skimage\n",
    "    image = imread(path_image)\n",
    "    \n",
    "    # resize the image\n",
    "    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    \n",
    "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    # image = np.expand_dims(image, axis=-1)\n",
    "    \n",
    "    # insert the image into X_test\n",
    "    X_test[i] = image\n",
    "    \n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb6d9d53-85a4-4605-bf70-9f9b237ff481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_masks = np.zeros((NUM_TEST_IMAGES, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, img in enumerate(selected):\n",
    "    path_image = os.path.join(base, 'outlines/tiles', image_id)\n",
    "    image = imread(path_image)\n",
    "    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    image = rgb2gray(image)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    test_masks[i] = image\n",
    "test_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d1283fd-3fda-4a61-8eb5-fc46e05a5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 09:16:28.145490: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-04 09:16:28.253554: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-04 09:16:28.640503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shaun/miniconda3/envs/tf/lib/\n",
      "2022-10-04 09:16:28.640558: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shaun/miniconda3/envs/tf/lib/\n",
      "2022-10-04 09:16:28.640562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdfd65f4-dad0-4bca-8bb8-eae8de46ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 224, 224, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 224, 224, 16  448         ['lambda[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 224, 224, 16  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 224, 224, 16  2320        ['dropout[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 112, 112, 32  4640        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 112, 112, 32  0           ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 112, 112, 32  9248        ['dropout_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 56, 56, 64)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 64)   36928       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 28, 28, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 28, 28, 128)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 28, 28, 128)  147584      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 128)  0          ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 14, 14, 256)  295168      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 14, 14, 256)  0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 09:16:36.933303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:36.940281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:36.941130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:36.941963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-04 09:16:36.942544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:36.943147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:36.943575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:37.286474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:37.286927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:37.287343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 09:16:37.287733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9705 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:11:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_9 (Conv2D)              (None, 14, 14, 256)  590080      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 28, 28, 128)  131200     ['conv2d_9[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 28, 256)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 28, 28, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 28, 28, 128)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 28, 28, 128)  147584      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 56, 56, 64)  32832       ['conv2d_11[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 56, 56, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 56, 56, 64)   73792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 56, 56, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 56, 56, 64)   36928       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 112, 112, 32  8224       ['conv2d_13[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 112, 112, 64  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 112, 112, 32  18464       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 112, 112, 32  0           ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 112, 112, 32  9248        ['dropout_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 224, 224, 16  2064       ['conv2d_15[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 224, 224, 32  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 224, 224, 16  4624        ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 224, 224, 16  0           ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 224, 224, 16  2320        ['dropout_8[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 224, 224, 1)  17          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# source: https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
    "\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ce4281-2c78-4040-bbd0-53dc42aed04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 21:21:09.807962: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1071307776 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0886\n",
      "Epoch 1: val_loss improved from inf to 0.08297, saving model to model.h5\n",
      "223/223 [==============================] - 44s 181ms/step - loss: 0.0886 - val_loss: 0.0830\n",
      "Epoch 2/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0856\n",
      "Epoch 2: val_loss did not improve from 0.08297\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0856 - val_loss: 0.0872\n",
      "Epoch 3/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0836\n",
      "Epoch 3: val_loss improved from 0.08297 to 0.08129, saving model to model.h5\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0836 - val_loss: 0.0813\n",
      "Epoch 4/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0849\n",
      "Epoch 4: val_loss did not improve from 0.08129\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0849 - val_loss: 0.0828\n",
      "Epoch 5/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0799\n",
      "Epoch 5: val_loss improved from 0.08129 to 0.08100, saving model to model.h5\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0799 - val_loss: 0.0810\n",
      "Epoch 6/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0788\n",
      "Epoch 6: val_loss improved from 0.08100 to 0.07797, saving model to model.h5\n",
      "223/223 [==============================] - 40s 182ms/step - loss: 0.0788 - val_loss: 0.0780\n",
      "Epoch 7/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0761\n",
      "Epoch 7: val_loss improved from 0.07797 to 0.07718, saving model to model.h5\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0761 - val_loss: 0.0772\n",
      "Epoch 8/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0748\n",
      "Epoch 8: val_loss improved from 0.07718 to 0.07542, saving model to model.h5\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0748 - val_loss: 0.0754\n",
      "Epoch 9/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0727\n",
      "Epoch 9: val_loss improved from 0.07542 to 0.07358, saving model to model.h5\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0727 - val_loss: 0.0736\n",
      "Epoch 10/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0739\n",
      "Epoch 10: val_loss did not improve from 0.07358\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0739 - val_loss: 0.0923\n",
      "Epoch 11/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0826\n",
      "Epoch 11: val_loss did not improve from 0.07358\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0826 - val_loss: 0.0797\n",
      "Epoch 12/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0729\n",
      "Epoch 12: val_loss did not improve from 0.07358\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0729 - val_loss: 0.0745\n",
      "Epoch 13/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0670\n",
      "Epoch 13: val_loss did not improve from 0.07358\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0670 - val_loss: 0.0748\n",
      "Epoch 14/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0650\n",
      "Epoch 14: val_loss improved from 0.07358 to 0.07184, saving model to model.h5\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0650 - val_loss: 0.0718\n",
      "Epoch 15/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0718\n",
      "Epoch 15: val_loss did not improve from 0.07184\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0718 - val_loss: 0.0739\n",
      "Epoch 16/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0658\n",
      "Epoch 16: val_loss improved from 0.07184 to 0.07182, saving model to model.h5\n",
      "223/223 [==============================] - 40s 181ms/step - loss: 0.0658 - val_loss: 0.0718\n",
      "Epoch 17/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0619\n",
      "Epoch 17: val_loss did not improve from 0.07182\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0619 - val_loss: 0.0741\n",
      "Epoch 18/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0597\n",
      "Epoch 18: val_loss did not improve from 0.07182\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0597 - val_loss: 0.0737\n",
      "Epoch 19/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0669\n",
      "Epoch 19: val_loss did not improve from 0.07182\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0669 - val_loss: 0.0759\n",
      "Epoch 20/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0590\n",
      "Epoch 20: val_loss did not improve from 0.07182\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0590 - val_loss: 0.0725\n",
      "Epoch 21/50\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0557\n",
      "Epoch 21: val_loss did not improve from 0.07182\n",
      "223/223 [==============================] - 40s 180ms/step - loss: 0.0557 - val_loss: 0.0726\n",
      "Epoch 21: early stopping\n"
     ]
    }
   ],
   "source": [
    "filepath = \"model.h5\"\n",
    "\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [earlystopper, checkpoint]\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.1, batch_size=32, epochs=50, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5741573-bbc5-4646-b201-4e3bfbcf11bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 09:16:51.520763: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-10-04 09:16:52.930364: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 09:16:54.452341: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "\n",
    "# use the best epoch\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3356b5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('/home/shaun/PHYS_391B/model.h5')\n",
    "\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "21bb3e54515daae9d0d545837835a72ec76dd4887079798748cf86d677f0608f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
